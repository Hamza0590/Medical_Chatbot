{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7935f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55329c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf():\n",
    "    loader = DirectoryLoader(\n",
    "        '../data',\n",
    "        glob='*.pdf',\n",
    "        loader_cls=PyPDFLoader\n",
    "    )   \n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64d320f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_pdf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bea70c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(Document(page_content=doc.page_content, metadata={\"source\": src}))\n",
    "    return minimal_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23ab46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = filter_to_minimal_docs(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff5c1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "\n",
    "    )\n",
    "    text = text_splitter.split_documents(documents)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbd02df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text chunks: 5859\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(doc)\n",
    "print(f\"Total number of text chunks: {len(text_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0fbcf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings_model():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings_model= HuggingFaceEmbeddings(\n",
    "    model_name=model_name\n",
    "    )\n",
    "    return embeddings_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ede2870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = download_embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43f32840",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = embeddings_model.embed_query(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc2e0c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9561cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone = os.getenv('PINECONE_API_KEY')\n",
    "os.environ[\"PINECONE_API_KEY\"] = pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77ecdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "pinecone_api_key = pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "14bbe096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x2120a49ce30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db32a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "index_name = \"medical-chatbot\"\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec = ServerlessSpec(cloud = \"aws\", region = \"us-east-1\")\n",
    "        )\n",
    "index = pc.Index(index_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abebc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "                documents= text_chunks,\n",
    "                embedding=  embeddings_model,\n",
    "                index_name=index_name\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a9a06",
   "metadata": {},
   "source": [
    "## If an index is laread available then you can load it in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "846ff41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name= index_name,\n",
    "    embedding=embeddings_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cb49f",
   "metadata": {},
   "source": [
    "## Add more data to the index Use this:\n",
    "    doc = Document(\n",
    "        page_content = \"Something\",\n",
    "        metadata = {\"source\": \"Something\"}\n",
    "    )\n",
    "    dosearch.add_documents(documets = [doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d704dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "121ba68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_docs = retriever.invoke(\"What is Anthrax?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "44c4a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='ee75da72-2b5f-450a-b7ab-8ce20c85b74b', metadata={'source': '..\\\\data\\\\Medical_book.pdf'}, page_content='Anthrax\\nDefinition\\nAnthrax is a bacterial infection caused by Bacillus\\nanthracis that primarily affects livestock but that can\\noccasionally spread to humans, affecting either the skin,\\nintestines, or lungs. In humans, the infection can often be\\ntreated, but it is almost always fatal in animals.\\nDescription\\nAnthrax is most often found in the agricultural\\nareas of South and Central America, southern and east-\\nern Europe, Asia, Africa, the Caribbean, and the Middle'),\n",
       " Document(id='3b6f15d0-26a8-4351-91dc-4a178b0dc8c4', metadata={'source': '..\\\\data\\\\Medical_book.pdf'}, page_content='Avenue Appia 20, 1211 Geneva 27, Switzerland. (+00 41\\n22) 791 21 11. <http://www.who.int>.\\nGALE ENCYCLOPEDIA OF MEDICINE 2 225\\nAnthrax\\nGEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 225'),\n",
       " Document(id='0ac46b11-dc2a-48f0-b345-925bd57a056e', metadata={'source': '..\\\\data\\\\Medical_book.pdf'}, page_content='East. In the United States, anthrax is rarely reported,\\nhowever, cases of animal infection with anthrax are\\nmost often reported in Texas, Louisiana, Mississippi,\\nOklahoma, and South Dakota. The bacterium and its\\nassociated disease get their name from the Greek word\\nmeaning “coal” because of the characteristic coal-black\\nsore that is the hallmark of the most common form of\\nthe disease.\\nDuring the 1800s, in England and Germany, anthrax\\nwas known either as “wool-sorter’s” or “ragpicker’s” dis-'),\n",
       " Document(id='179e1b6b-39f6-4c26-8eac-bb702c9c369e', metadata={'source': '..\\\\data\\\\Medical_book.pdf'}, page_content='by, if present in the sample, the anthrax bacterium is\\nmade to fluoresce. Blood samples will also indicate ele-\\nvated antibody levels or increased amounts of a protein\\nproduced directly in response to infection with the\\nanthrax bacterium. Additional DNA-based tests are also\\ncurrently being perfected.\\nTreatment\\nIn the early stages, anthrax is curable by administering\\nhigh doses of penicillin, but in the advanced stages, it can\\nbe fatal. Other commonly used antibiotics, such as ery-'),\n",
       " Document(id='e398ab0f-e48b-441c-857f-714a90d57d2c', metadata={'source': '..\\\\data\\\\Medical_book.pdf'}, page_content='vomiting, loss of appetite, and fever, followed by abdomi-\\nnal pain, vomiting of blood, and severe bloody diarrhea.\\nDiagnosis\\nAnthrax is diagnosed by detecting B. anthracis in\\nsamples taken from blood, skin lesions , or respiratory\\nsecretions. The bacteria may be positively identified\\nusing biochemical methods or using a technique where-\\nGALE ENCYCLOPEDIA OF MEDICINE 2224\\nAnthrax\\nHumans suffering from anthrax often develop ulcerating\\nnodules on the body.Custom Medical Stock Photo. Repro-')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9268184",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     33\u001b[39m     response = llm.invoke(prompt)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.content\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m response = \u001b[43mgeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is anthrax?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[97]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mgeneration\u001b[39m\u001b[34m(query, retriever)\u001b[39m\n\u001b[32m     27\u001b[39m user_prompt = HumanMessagePromptTemplate.from_template(\n\u001b[32m     28\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{query}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m prompt = ChatPromptTemplate.from_messages([system_prompt , user_prompt])\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamza\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:399\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    398\u001b[39m             \u001b[38;5;28mself\u001b[39m.generate_prompt(\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m                 [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m],\n\u001b[32m    400\u001b[39m                 stop=stop,\n\u001b[32m    401\u001b[39m                 callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    402\u001b[39m                 tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    403\u001b[39m                 metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    404\u001b[39m                 run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    405\u001b[39m                 run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    406\u001b[39m                 **kwargs,\n\u001b[32m    407\u001b[39m             ).generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hamza\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:382\u001b[39m, in \u001b[36mBaseChatModel._convert_input\u001b[39m\u001b[34m(self, model_input)\u001b[39m\n\u001b[32m    377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages=convert_to_messages(model_input))\n\u001b[32m    378\u001b[39m msg = (\n\u001b[32m    379\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    380\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMust be a PromptValue, str, or list of BaseMessages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    381\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Invalid input type <class 'langchain_core.prompts.chat.ChatPromptTemplate'>. Must be a PromptValue, str, or list of BaseMessages."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "# Set your key\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = groq_api_key\n",
    "\n",
    "\n",
    "def generation(query, retriever):\n",
    "    llm = ChatGroq(\n",
    "            model_name=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.5\n",
    "        )\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful medical assistant.\" \n",
    "    \"Based only on the context below, answer the question concisely and clearly.\"\n",
    "    \"If you do not have enough information, say so. Use three sentence maximum\"\n",
    "    \"and keep the answer consice.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    "    )\n",
    "\n",
    "    user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"Question: {query}\")\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([system_prompt , user_prompt])\n",
    "\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "\n",
    "    return response.content\n",
    "response = generation(\"What is anthrax?\", retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8dc688e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthrax is a bacterial infection caused by Bacillus anthracis that primarily affects livestock but can occasionally spread to humans. It can affect the skin, intestines, or lungs in humans, and while it can often be treated, it is almost always fatal in animals. The infection is characterized by a coal-black sore and can be diagnosed through blood, skin, or respiratory secretion samples.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae9bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
